{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "import wave\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_DIRECTORY = \"./raw_data/positive_data/\"\n",
    "BACKGROUND_DIRECTORY = \"./raw_data/background_data/\"\n",
    "NEGATIVES_DIRECTORY = \"./raw_data/google_dataset/\"\n",
    "NEGATIVES_TRUNCATED_DIRECTORY = \"./raw_data/google_dataset_truncated/\"\n",
    "AUDIO_EXAMPLES_DIRECTORY = \"./audio_examples/\"\n",
    "AUDIO_IGNORED_EXAMPLES_DIRECTORY = \"./audio_ignored_examples/\"\n",
    "\n",
    "POSITIVE_EXAMPLE = \"jh_1.wav\"\n",
    "BACKGROUND_EXAMPLE = \"bg_10.wav\"\n",
    "\n",
    "AUDIO_EXAMPLE = \"example_train.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Approach\n",
    "\n",
    "The general idea is randomly iterate through each word directory, randomly select a recording from each word directory, and concatenating the words to form a ten second continuous stream of words.\n",
    "\n",
    "For now, collect 9 words, select a background, put the 9 words inside, put basically inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVES_FILENAMES = [name for name in os.listdir(NEGATIVES_DIRECTORY) if os.path.isdir(os.path.join(NEGATIVES_DIRECTORY, name)) \n",
    "                       and '_' not in name]\n",
    "NEGATIVES_AUDIONAMES = {}\n",
    "for file in NEGATIVES_FILENAMES:\n",
    "    NEGATIVES_AUDIONAMES[file] = [name for name in os.listdir(NEGATIVES_DIRECTORY + file + \"/\") if name.endswith(\"wav\")]\n",
    "POSITIVES_AUDIONAMES = [name for name in os.listdir(POSITIVE_DIRECTORY) if name.endswith(\"wav\")]\n",
    "BACKGROUND_AUDIONAMES = [name for name in os.listdir(BACKGROUND_DIRECTORY) if name.endswith(\"wav\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5490 # Based on created training example\n",
    "n_freq = 129 # Based on created training example\n",
    "Ty = 1369 # Based on model.summary() in 1.4 with shape := (Tx, n_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones(y, segment_end_ms):\n",
    "    \"\"\"\n",
    "    Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
    "    should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
    "    50 followinf labels should be ones.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    y -- numpy array of shape (1, Ty), the labels of the training example\n",
    "    segment_end_ms -- the end time of the segment in ms\n",
    "    \n",
    "    Returns:\n",
    "    y -- updated labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # duration of the background (in terms of spectrogram time-steps)\n",
    "    segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
    "    # Add 1 to the correct index in the background label (y)\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    for i in range(segment_end_y + 1, segment_end_y + 51):\n",
    "        if i < Ty:\n",
    "            y[0, i] = 1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y\n",
    "\n",
    "def random_negatives(negative_audionames, n, debug=False):\n",
    "    \"\"\"\n",
    "    Given a python dictionary of all audio names in negative files\n",
    "    Return a list of n randomly selected negative audios\n",
    "    \"\"\"\n",
    "    \n",
    "    # find n random files\n",
    "    random_files = np.random.choice(list(negative_audionames.keys()), n, replace=False)\n",
    "    output = []\n",
    "    if debug:\n",
    "        print(\"Selecting {} negative audio files randomly:\".format(n))\n",
    "    audio_length = 0\n",
    "    for file in random_files:\n",
    "        audio_names = negative_audionames[file]\n",
    "        # from each file generate a random audio\n",
    "        random_audio = np.random.choice(audio_names, 1)[0]\n",
    "        if debug:\n",
    "            print(\"    - from {}: {}\".format(file, random_audio))\n",
    "        # load the chosen audio\n",
    "        global NEGATIVES_DIRECTORY\n",
    "        link = NEGATIVES_DIRECTORY + file + \"/\" + random_audio\n",
    "        audio = AudioSegment.from_wav(link)\n",
    "        audio_length += len(audio)\n",
    "        output.append(audio)\n",
    "    return output, audio_length\n",
    "\n",
    "def random_positives(positives_audionames, n, debug=False):\n",
    "    \"\"\"\n",
    "    Given a list of positive audio names\n",
    "    Return a list of 0-4 randomly selected positive audios\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate n random audios\n",
    "    random_audios = np.random.choice(positives_audionames, n, replace=False)\n",
    "    output = []\n",
    "    if debug:\n",
    "        print(\"Selecting {} positive audio files randomly:\".format(n))\n",
    "    audio_length = 0\n",
    "    for name in random_audios:\n",
    "        if debug:\n",
    "            print(\"    - {}\".format(name))\n",
    "        # load audio\n",
    "        global POSITIVE_DIRECTORY\n",
    "        link = POSITIVE_DIRECTORY + name\n",
    "        audio = AudioSegment.from_wav(link)\n",
    "        audio_length += len(audio)\n",
    "        output.append(audio)\n",
    "    return output, audio_length\n",
    "\n",
    "def random_background(background_audionames, debug=False):\n",
    "    \"\"\"\n",
    "    Given a list of background audio names\n",
    "    Return a randomly selected background audio\n",
    "    \"\"\"\n",
    "    # generate a random audio\n",
    "    random_audio = np.random.choice(background_audionames, 1, replace=False)[0]\n",
    "    if debug:\n",
    "        print(\"Selecting background file randomly:\\n    - {}\".format(random_audio))\n",
    "    # load audio\n",
    "    global BACKGROUND_DIRECTORY\n",
    "    link = BACKGROUND_DIRECTORY + random_audio\n",
    "    return AudioSegment.from_wav(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(id, prefix, debug=False):\n",
    "    \"\"\"\n",
    "    Creates a training examples with a given background, positives, and negatives with id.\n",
    "    \n",
    "    Arguments:\n",
    "    id -- an id is given such that the new files does not replace the previous files\n",
    "    \n",
    "    Returns:\n",
    "    x -- the spectrogram of the training example\n",
    "    y -- the label at each time step of the spectrogram\n",
    "    \"\"\"\n",
    "    negatives, neg_len = random_negatives(NEGATIVES_AUDIONAMES, 9, debug)\n",
    "    positives, pos_len = random_positives(POSITIVES_AUDIONAMES, 1, debug)\n",
    "    background = random_background(BACKGROUND_AUDIONAMES, debug)\n",
    "    \n",
    "    # Make background quieter\n",
    "    background = background - 30\n",
    "    \n",
    "    # Initialize y (label vector) of zeros (≈ 1 line)\n",
    "    y = np.zeros((1, Ty))\n",
    "    \n",
    "    # Squeeze in as many negatives as possible within 10 seconds\n",
    "    total_len = neg_len + pos_len\n",
    "    while total_len > 10000:\n",
    "        to_remove = np.random.randint(0, len(negatives))\n",
    "        negatives.pop(to_remove)\n",
    "        total_len = pos_len\n",
    "        for audio in negatives:\n",
    "            total_len += len(audio)\n",
    "\n",
    "    # Randomly insert positives into negatives\n",
    "    insertion_points = list(np.random.choice(list(range(len(negatives)+1)), len(positives), replace=False))\n",
    "    insertion_points.sort()\n",
    "    num_inserted = 0\n",
    "    inserted_points = []\n",
    "    while len(insertion_points) > 0:\n",
    "        insertion_point = insertion_points.pop(0) + num_inserted\n",
    "        negatives.insert(insertion_point, positives[num_inserted])\n",
    "        num_inserted += 1\n",
    "        inserted_points.append(insertion_point)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Points of insertion: {}\".format(inserted_points))\n",
    "    \n",
    "    # Concatenate audios and insert labels\n",
    "    continuous = negatives[0]\n",
    "    audio_length = len(continuous)\n",
    "    if 0 in inserted_points:\n",
    "        y = insert_ones(y, segment_end_ms=len(continuous))\n",
    "\n",
    "    for i in range(1,len(negatives)):\n",
    "        continuous += negatives[i]\n",
    "        # insert label\n",
    "        if i in inserted_points:\n",
    "            y = insert_ones(y, segment_end_ms=len(continuous))\n",
    "\n",
    "\n",
    "    # Superpose audio segment and background\n",
    "    result = background.overlay(continuous, position = 0)\n",
    "    # trim off any excess\n",
    "    result = result[:10000]\n",
    "\n",
    "    # Export new training example \n",
    "    result = result.set_channels(1)\n",
    "    result = result.set_frame_rate(123000)\n",
    "    \n",
    "    file_handle = result.export(AUDIO_IGNORED_EXAMPLES_DIRECTORY + prefix + \"_\" + str(id) + \".wav\", format=\"wav\")\n",
    "    if debug:\n",
    "        print(\"File (train_\" + str(id) + \".wav) was saved in \" + AUDIO_IGNORED_EXAMPLES_DIRECTORY)\n",
    "\n",
    "    sample_rate, samples = wavfile.read(AUDIO_IGNORED_EXAMPLES_DIRECTORY + prefix + \"_\" + str(id) +\".wav\")\n",
    "    frequencies, times, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    return frequencies, times, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 9 negative audio files randomly:\n",
      "    - from sheila: b00dff7e_nohash_1.wav\n",
      "    - from down: 763188c4_nohash_4.wav\n",
      "    - from cat: 37d38e44_nohash_0.wav\n",
      "    - from one: 439c84f4_nohash_2.wav\n",
      "    - from go: 8e05039f_nohash_3.wav\n",
      "    - from off: 02e85b60_nohash_0.wav\n",
      "    - from bed: e3e49931_nohash_0.wav\n",
      "    - from yes: 7ca023e2_nohash_0.wav\n",
      "    - from eight: 5b1db3ee_nohash_0.wav\n",
      "Selecting 1 positive audio files randomly:\n",
      "    - yb_6.wav\n",
      "Selecting background file randomly:\n",
      "    - bg_62.wav\n",
      "Points of insertion: [5]\n",
      "File (train_1.wav) was saved in ./audio_ignored_examples/\n",
      "x: (129, 5490)\n",
      "y: (1, 1369)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x115bac410>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "frequencies, times, x, y = create_training_example(1, \"train\", debug=True)\n",
    "print(\"x: {}\".format(x.shape))\n",
    "print(\"y: {}\".format(y.shape))\n",
    "plt.plot(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix refers to the prefix naming of output audio files\n",
    "def create_X_Y(size, start, prefix):\n",
    "    i, X, Y = 1, [], []\n",
    "    for i in range(start, start + size):\n",
    "        frequencies, times, x, y = create_training_example(i, prefix)\n",
    "        x = np.transpose(x)\n",
    "        y = np.transpose(y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return (np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "\n",
    "Training data is generated 1000 examples at a time since there is not enough RAM on my computer :( Either ways, we can still do incremental training of the model per batch of 1000 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './audio_ignored_examples/dev1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-afe4f1835035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_X_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X:{} Y:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training_data/dev_set/X_dev.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training_data/dev_set/Y_dev.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-911a8b904467>\u001b[0m in \u001b[0;36mcreate_X_Y\u001b[0;34m(size, start, prefix)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfrequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_training_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-7adf0b9c724c>\u001b[0m in \u001b[0;36mcreate_training_example\u001b[0;34m(id, prefix, debug)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File (train_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".wav) was saved in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAUDIO_IGNORED_EXAMPLES_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_IGNORED_EXAMPLES_DIRECTORY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\".wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mfrequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './audio_ignored_examples/dev1.wav'"
     ]
    }
   ],
   "source": [
    "X, Y = create_X_Y(50, 1, \"dev\")\n",
    "print(\"X:{} Y:{}\".format(X.shape, Y.shape))\n",
    "np.save(\"./training_data/dev_set/X_dev.npy\", X)\n",
    "np.save(\"./training_data/dev_set/Y_dev.npy\", Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Improvements:\n",
    "- Randomly insert miliseconds of spaces within each sound to fully fill up all the 10 seconds.\n",
    "- Try to cut off the positives' empty sounds at the start and at the end. There are only so few positives so might be possible to manually do it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
