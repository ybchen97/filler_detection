{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filler Word Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data synthesis: Creating a speech dataset\n",
    "### 1.1 - Listening to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "import wave\n",
    "import pylab\n",
    "from tf_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Import files for trigger-word detection model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring Environment Variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_DIRECTORY = \"./raw_data/positive_data/\"\n",
    "BACKGROUND_DIRECTORY = \"./raw_data/background_data/\"\n",
    "NEGATIVES_DIRECTORY = \"./raw_data/google_dataset/\"\n",
    "NEGATIVES_TRUNCATED_DIRECTORY = \"./raw_data/google_dataset_truncated/\"\n",
    "AUDIO_EXAMPLES_DIRECTORY = \"./audio_examples/\"\n",
    "AUDIO_IGNORED_EXAMPLES_DIRECTORY = \"./audio_ignored_examples/\"\n",
    "POSITIVE_EXAMPLE = \"jh_1.wav\"\n",
    "AUDIO_EXAMPLE = \"example_train.wav\"\n",
    "STUB_TRAIN_DIRECTORY = \"./stub_data/XY_Train/\"\n",
    "STUB_DEV_DIRECTORY = \"./stub_data/XY_Dev/\"\n",
    "STUB_MODEL = \"./stub_data/models/tr_model.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading raw audio files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play(AudioSegment.from_file(POSITIVE_DIRECTORY + POSITIVE_EXAMPLE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions needed for 1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones(y, segment_end_ms):\n",
    "    \"\"\"\n",
    "    Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
    "    should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
    "    50 followinf labels should be ones.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    y -- numpy array of shape (1, Ty), the labels of the training example\n",
    "    segment_end_ms -- the end time of the segment in ms\n",
    "    \n",
    "    Returns:\n",
    "    y -- updated labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # duration of the background (in terms of spectrogram time-steps)\n",
    "    segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
    "    \n",
    "    # Add 1 to the correct index in the background label (y)\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    for i in range(segment_end_y + 1, segment_end_y + 51):\n",
    "        if i < Ty:\n",
    "            y[0, i] = 1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_time_segment(segment_ms):\n",
    "    \"\"\"\n",
    "    Gets a random time segment of duration segment_ms in a 10,000 ms audio clip.\n",
    "    \n",
    "    Arguments:\n",
    "    segment_ms -- the duration of the audio clip in ms (\"ms\" stands for \"milliseconds\")\n",
    "    \n",
    "    Returns:\n",
    "    segment_time -- a tuple of (segment_start, segment_end) in ms\n",
    "    \"\"\"\n",
    "    \n",
    "    segment_start = np.random.randint(low=0, high=10000-segment_ms)   # Make sure segment doesn't run past the 10sec background \n",
    "    segment_end = segment_start + segment_ms - 1\n",
    "    \n",
    "    return (segment_start, segment_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(segment_time, previous_segments):\n",
    "    \"\"\"\n",
    "    Checks if the time of a segment overlaps with the times of existing segments.\n",
    "    \n",
    "    Arguments:\n",
    "    segment_time -- a tuple of (segment_start, segment_end) for the new segment\n",
    "    previous_segments -- a list of tuples of (segment_start, segment_end) for the existing segments\n",
    "    \n",
    "    Returns:\n",
    "    True if the time segment overlaps with any of the existing segments, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    segment_start, segment_end = segment_time\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 line)\n",
    "    # Step 1: Initialize overlap as a \"False\" flag. (≈ 1 line)\n",
    "    overlap = False\n",
    "    \n",
    "    # Step 2: loop over the previous_segments start and end times.\n",
    "    # Compare start/end times and set the flag to True if there is an overlap (≈ 3 lines)\n",
    "    for previous_start, previous_end in previous_segments:\n",
    "        if segment_start <= previous_end and segment_end >= previous_start:\n",
    "            overlap = True\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return overlap\n",
    "\n",
    "overlap1 = is_overlapping((950, 1430), [(2000, 2550), (260, 949)])\n",
    "overlap2 = is_overlapping((2305, 2950), [(824, 1532), (1900, 2305), (3424, 3656)])\n",
    "\n",
    "assert overlap1 == False, \"Should not overlap.\"\n",
    "assert overlap2 == True, \"Should overlap.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_audio_clip(background, audio_clip, previous_segments):\n",
    "    \"\"\"\n",
    "    Insert a new audio segment over the background noise at a random time step, ensuring that the \n",
    "    audio segment does not overlap with existing segments.\n",
    "    \n",
    "    Arguments:\n",
    "    background -- a 10 second background audio recording.  \n",
    "    audio_clip -- the audio clip to be inserted/overlaid. \n",
    "    previous_segments -- times where audio segments have already been placed\n",
    "    \n",
    "    Returns:\n",
    "    new_background -- the updated background audio\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the duration of the audio clip in ms\n",
    "    segment_ms = len(audio_clip)\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Use one of the helper functions to pick a random time segment onto which to insert \n",
    "    # the new audio clip. (≈ 1 line)\n",
    "    segment_time = get_random_time_segment(segment_ms)\n",
    "    \n",
    "    # Step 2: Check if the new segment_time overlaps with one of the previous_segments. If so, keep \n",
    "    # picking new segment_time at random until it doesn't overlap. (≈ 2 lines)\n",
    "    while is_overlapping(segment_time, previous_segments):\n",
    "        segment_time = get_random_time_segment(segment_ms)\n",
    "\n",
    "    # Step 3: Add the new segment_time to the list of previous_segments (≈ 1 line)\n",
    "    previous_segments.append(segment_time)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 4: Superpose audio segment and background\n",
    "    new_background = background.overlay(audio_clip, position = segment_time[0])\n",
    "    \n",
    "    return new_background, segment_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1\n",
    "\n",
    "Instead of loading the entire dataset, only the names of files and audios are loaded. They are stored in a python dictionary. Each time a random audio is to be selected, randomly choose a name from the dictionary and look for corresponding audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5490 # Based on created training example\n",
    "n_freq = 129 # Based on created training example\n",
    "Ty = 1369 # Based on model.summary() in 1.4 with shape := (Tx, n_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVES_FILENAMES = [name for name in os.listdir(NEGATIVES_DIRECTORY) if os.path.isdir(os.path.join(NEGATIVES_DIRECTORY, name)) \n",
    "                       and '_' not in name]\n",
    "NEGATIVES_AUDIONAMES = {}\n",
    "for file in NEGATIVES_FILENAMES:\n",
    "    NEGATIVES_AUDIONAMES[file] = [name for name in os.listdir(NEGATIVES_DIRECTORY + file + \"/\") if name.endswith(\"wav\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_element(lst, n):\n",
    "    \"\"\"\n",
    "    Assume n <= len(lst)\n",
    "    Return n elements randomly from lst\n",
    "    \"\"\"\n",
    "    random_index = np.random.randint(len(lst), size = n)\n",
    "    return [lst[i] for i in random_index]\n",
    "\n",
    "def random_negatives(negative_audionames):\n",
    "    \"\"\"\n",
    "    Given a python dictionary of all audio names in negative files\n",
    "    Return a list of 0-2 randomly selected negative audios\n",
    "    \"\"\"\n",
    "    # determine number of negatives to generate: 0-2\n",
    "    num_neg = np.random.randint(0, 3)\n",
    "    if num_neg == 0:\n",
    "        return []\n",
    "    # find 0-2 random file\n",
    "    random_files = random_element(list(negative_audionames.keys()), num_neg)\n",
    "    output = []\n",
    "    for file in random_files:\n",
    "        audio_names = negative_audionames[file]\n",
    "        # from each file generate a random audio\n",
    "        random_audio = random_element(audio_names, 1)[0]\n",
    "        # load the chosen audio\n",
    "        global NEGATIVES_DIRECTORY\n",
    "        link = NEGATIVES_DIRECTORY + file + \"/\" + random_audio\n",
    "        audio = AudioSegment.from_wav(link)\n",
    "        output.append(audio)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test case:\n",
    "# neg = random_negatives(NEGATIVES_AUDIONAMES)\n",
    "# if len(neg) > 0:\n",
    "#     play(neg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for positive and background audios, the names of audios are loaded and stored in two lists. Each time a random audio is to be selected, randomly choose a name from the dictionary and look for corresponding audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVES_AUDIONAMES = [name for name in os.listdir(POSITIVE_DIRECTORY) if name.endswith(\"wav\")]\n",
    "BACKGROUND_AUDIONAMES = [name for name in os.listdir(BACKGROUND_DIRECTORY) if name.endswith(\"wav\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_positives(positives_audionames):\n",
    "    \"\"\"\n",
    "    Given a list of positive audio names\n",
    "    Return a list of 0-4 randomly selected positive audios\n",
    "    \"\"\"\n",
    "    # determine number of positives to generate: 0-4\n",
    "    num_pos = np.random.randint(0, 5)\n",
    "    if num_pos == 0:\n",
    "        return []\n",
    "    # generate n random audios\n",
    "    random_audios = random_element(positives_audionames, num_pos)\n",
    "    output = []\n",
    "    for name in random_audios:\n",
    "        # load audio\n",
    "        global POSITIVE_DIRECTORY\n",
    "        link = POSITIVE_DIRECTORY + name\n",
    "        audio = AudioSegment.from_wav(link)\n",
    "        output.append(audio)\n",
    "    return output\n",
    "\n",
    "def random_background(background_audionames):\n",
    "    \"\"\"\n",
    "    Given a list of background audio names\n",
    "    Return a randomly selected background audio\n",
    "    \"\"\"\n",
    "    # generate a random audio\n",
    "    random_audio = random_element(background_audionames, 1)[0]\n",
    "    # load audio\n",
    "    global BACKGROUND_DIRECTORY\n",
    "    link = BACKGROUND_DIRECTORY + random_audio\n",
    "    return AudioSegment.from_wav(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test case 1:\n",
    "# pos = random_positives(POSITIVES_AUDIONAMES)\n",
    "# if len(pos) > 0:\n",
    "#     play(pos[0])\n",
    "# # Test case 2:\n",
    "# bg = random_background(BACKGROUND_AUDIONAMES)\n",
    "# play(bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function cannot_insert to detect situation when no available time slot can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannot_insert(audio_clip, previous_segments):\n",
    "    \"\"\"\n",
    "    Check if it's impossible to insert an audio clip to the current background.\n",
    "    \"\"\"\n",
    "    if len(previous_segments) == 0:\n",
    "        return False\n",
    "    segment_ms = len(audio_clip)\n",
    "    start_end_points = [-1, 10001]\n",
    "    for start, end in previous_segments:\n",
    "        start_end_points.append(start)\n",
    "        start_end_points.append(end)\n",
    "    start_end_points.sort()\n",
    "    for i in list(range(len(start_end_points)))[::2]:\n",
    "        available_length = start_end_points[i+1] - start_end_points[i] - 1\n",
    "        if available_length >= segment_ms:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case\n",
    "test_audio = AudioSegment.from_wav(POSITIVE_DIRECTORY + POSITIVE_EXAMPLE)\n",
    "print(len(test_audio))\n",
    "print(cannot_insert(test_audio, [(2071, 3000), (5072, 6000), (8072, 9000)])) # No available slot possible\n",
    "print(cannot_insert(test_audio, [(1000, 2000), (3000, 4000)])) # Available slot present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create_training_example function is then modified to adapt to above changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(id):\n",
    "    \"\"\"\n",
    "    Creates a training examples with a given background, positives, and negatives with id.\n",
    "    \n",
    "    Arguments:\n",
    "    id -- an id is given such that the new files does not replace the previous files\n",
    "    \n",
    "    Returns:\n",
    "    x -- the spectrogram of the training example\n",
    "    y -- the label at each time step of the spectrogram\n",
    "    \"\"\"\n",
    "    global BACKGROUND_AUDIONAMES\n",
    "    global POSITIVES_AUDIONAMES\n",
    "    global NEGATIVES_AUDIONAMES\n",
    "    \n",
    "    background = random_background(BACKGROUND_AUDIONAMES)\n",
    "    positives = random_positives(POSITIVES_AUDIONAMES)\n",
    "    negatives = random_negatives(NEGATIVES_AUDIONAMES)\n",
    "    \n",
    "    # Make background quieter\n",
    "    background = background - 20\n",
    "    \n",
    "    # Step 1: Initialize y (label vector) of zeros (≈ 1 line)\n",
    "    y = np.zeros((1, Ty))\n",
    "\n",
    "    # Step 2: Initialize segment times as empty list (≈ 1 line)\n",
    "    previous_segments = []    \n",
    "    \n",
    "    # Step 3: Loop over randomly selected \"activate\" clips and insert in background\n",
    "    for random_positive in positives:\n",
    "        if cannot_insert(random_positive, previous_segments):\n",
    "            return create_training_example(id)\n",
    "        # Insert the audio clip on the background\n",
    "        background, segment_time = insert_audio_clip(background, random_positive, previous_segments)\n",
    "        # Retrieve segment_start and segment_end from segment_time\n",
    "        segment_start, segment_end = segment_time\n",
    "        # Insert labels in \"y\"\n",
    "        y = insert_ones(y, segment_end_ms=segment_end)\n",
    "\n",
    "    # Step 4: Loop over randomly selected negative clips and insert in background\n",
    "    for random_negative in negatives:\n",
    "        if cannot_insert(random_negative, previous_segments):\n",
    "            return create_training_example(id)\n",
    "        # Insert the audio clip on the background \n",
    "        background, _ = insert_audio_clip(background, random_negative, previous_segments)\n",
    "\n",
    "    # Export new training example \n",
    "    background = background.set_channels(1)\n",
    "    background = background.set_frame_rate(123000)\n",
    "    \n",
    "    TRAIN_PREFIX = \"train_\"\n",
    "    file_handle = background.export(AUDIO_EXAMPLES_DIRECTORY + TRAIN_PREFIX + str(id) + \".wav\", format=\"wav\")\n",
    "    # print(\"File (train_\" + str(id) + \".wav) was saved in your directory.\")\n",
    "\n",
    "    sample_rate, samples = wavfile.read(AUDIO_EXAMPLES_DIRECTORY + TRAIN_PREFIX + str(id) +\".wav\")\n",
    "    frequencies, times, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    return frequencies, times, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Test case:\n",
    "# frequencies, times, x, y = create_training_example(1)\n",
    "# IPython.display.Audio(AUDIO_EXAMPLES_DIRECTORY + \"train_1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking x and y shapes\n",
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_Y(size, start):\n",
    "    i, X, Y = 1, [], []\n",
    "    for i in range(start, start + size):\n",
    "        frequencies, times, x, y = create_training_example(i)\n",
    "        x = np.transpose(x)\n",
    "        y = np.transpose(y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return (np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "\n",
    "Training data is generated 1000 examples at a time since there is not enough RAM on my computer :( Either ways, we can still do incremental training of the model per batch of 1000 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(1000, 5490, 129) Y:(1000, 1369, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_X_Y(1000, 4000)\n",
    "print(\"X:{} Y:{}\".format(X.shape, Y.shape))\n",
    "np.save(\"./training_data/X_5.npy\", X)\n",
    "np.save(\"./training_data/Y_5.npy\", Y)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
