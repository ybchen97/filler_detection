{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ybchen97/filler_detection/blob/training-examples-generation/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "my6I-6tlRSuK"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAbmFvBVRXtY"
   },
   "source": [
    "Syncing from google drive and github... for more info on this code, refer [here](https://zerowithdot.com/colab-github-workflow/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FO4R_OEE3LSV"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from os.path import join\n",
    "from scipy import signal\n",
    "\n",
    "ROOT = '/content/drive'     # default for the drive\n",
    "PROJ = 'My Drive/filler_detection/train_data/XY_Train'       # path to your project on Drive\n",
    "\n",
    "drive.mount(ROOT)           # we mount the drive at /content/drive\n",
    "\n",
    "PROJECT_PATH = join(ROOT, PROJ)\n",
    "!mkdir \"{PROJECT_PATH}\"     # in case we haven't created it already   \n",
    "\n",
    "GIT_PATH = \"https://github.com/ybchen97/filler_detection.git\"\n",
    "!mkdir ./temp\n",
    "!git clone \"{GIT_PATH}\"\n",
    "!mv ./temp/* \"{PROJECT_PATH}\"\n",
    "!rm -rf ./temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qa4hVHm5RouU"
   },
   "source": [
    "Install packages in this local notebook specified in requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3SSCyXL8lBb"
   },
   "outputs": [],
   "source": [
    "!pip install -r '/content/filler_detection/requirements.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7Hn1LtPRxZS"
   },
   "source": [
    "Importing and setting up env variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1rasqjnO6mAq",
    "outputId": "52afff24-30ef-4445-8a11-4b976651aa4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "import wave\n",
    "import pylab\n",
    "from tf_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Import files for trigger-word detection model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shTwr2KwE6MW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from os.path import join\n",
    "\n",
    "ROOT = '/content/drive'     # default for the drive\n",
    "PROJ = 'My Drive/filler_detection/train_data/XY_Train'       # path to your project on Drive\n",
    "\n",
    "DATA_PATH = join(ROOT, PROJ)\n",
    "REPO = \"/content/filler_detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lgJ6UdH9ViH"
   },
   "outputs": [],
   "source": [
    "POSITIVE_DIRECTORY = \"./raw_data/positive_data/\"\n",
    "BACKGROUND_DIRECTORY = \"./raw_data/background_data/\"\n",
    "NEGATIVES_DIRECTORY = \"./raw_data/google_dataset/\"\n",
    "NEGATIVES_TRUNCATED_DIRECTORY = \"./raw_data/google_dataset_truncated/\"\n",
    "AUDIO_EXAMPLES_DIRECTORY = \"./audio_examples/\"\n",
    "POSITIVE_EXAMPLE = \"jh_1.wav\"\n",
    "AUDIO_EXAMPLE = \"example_train.wav\"\n",
    "CHIME_FILE = \"./filler_detection/audio_examples/chime.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9eM15MVGR0eJ"
   },
   "source": [
    "The fun begins...\n",
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b54E5A1c8pSh"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras library.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    \n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Step 1: CONV Layer\n",
    "    # CONV-1D\n",
    "    X = Conv1D(filters=196, kernel_size=15, strides=4)(X_input)\n",
    "    # Batch Normalization\n",
    "    X = BatchNormalization()(X)\n",
    "    # RelU activation\n",
    "    X = Activation(\"relu\")(X)\n",
    "    # Dropout (using rate 0.8)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    \n",
    "    # Step 2: First GRU Layer\n",
    "    # GRU (use 128 units to return the sequences)\n",
    "    X = GRU(units=128, return_sequences=True)(X)\n",
    "    # Dropout (using rate 0.8)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    # Batch Normalization\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    # Step 3: Second GRU Layer\n",
    "    # GRU (use 128 units to return the sequences)\n",
    "    X = GRU(units=128, return_sequences=True)(X)\n",
    "    # Dropout (using rate 0.8)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    # Batch Normalization\n",
    "    X = BatchNormalization()(X)\n",
    "    # Dropout (using rate 0.8)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    \n",
    "    # Step 4: Time-distributed dense layer\n",
    "    X = TimeDistributed(Dense(1, activation=\"sigmoid\"))(X)\n",
    "    \n",
    "    # Return model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEfBQCPhR2QQ"
   },
   "source": [
    "Sanity check for `Tx`, `n_freq`, `Ty`. \n",
    "\n",
    "1. Input into model `Tx` and `n_freq`\n",
    "2. Call `model.summary()`\n",
    "3. `Tx` of **sample** and variable = `input_7.shape[1]` (ie column 2, row 1, second element of array)\n",
    "4. `Ty` = `input_7.shape[1]` (ie column 2, row 2, second element of array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqW78CpL8sYH"
   },
   "outputs": [],
   "source": [
    "Tx = 5490 # The number of time steps input to the model from the spectrogram\n",
    "n_freq = 129 # Number of frequencies input to the model at each time step of the spectrogram\n",
    "Ty = 1369 # The number of time steps in the output of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2szTzk7Eh01"
   },
   "source": [
    "### Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "4o7XUQnaDQp8",
    "outputId": "6237ce5b-fa28-404c-fab8-6c7024a158d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5490, 129)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1369, 196)         379456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1369, 196)         784       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1369, 196)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1369, 196)         0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 1369, 128)         124800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1369, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1369, 128)         512       \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 1369, 128)         98688     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1369, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1369, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1369, 128)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 1369, 1)           129       \n",
      "=================================================================\n",
      "Total params: 604,881\n",
      "Trainable params: 603,977\n",
      "Non-trainable params: 904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"filler_detection/trained_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEezPsKZEnUh"
   },
   "source": [
    "### Create New Model (if no pre-trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3Sfny3t78rK"
   },
   "outputs": [],
   "source": [
    "model = model(input_shape = (Tx, n_freq))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owDLV1UyENRt"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYzGhjq78vL-"
   },
   "outputs": [],
   "source": [
    "# Function to fit and further train the model\n",
    "def model_train(model, X, Y):\n",
    "    \"\"\"\n",
    "    Function to train the model further using Adam optimiser and binary \n",
    "    cross entropy loss.\n",
    "    \n",
    "    Arguments:\n",
    "    model -- Model to train\n",
    "    X -- X data to train on\n",
    "    Y -- Y data to train on\n",
    "    \"\"\"\n",
    "    \n",
    "    opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X, Y, batch_size=5, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "0Z7c9Pha8wkw",
    "outputId": "77aceeed-bb01-43de-c9da-82ab9d8d5a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20/20 [==============================] - 17s 842ms/step - loss: 1.2381 - accuracy: 0.5025\n"
     ]
    }
   ],
   "source": [
    "# Train the model on stubbed data downloaded from Coursera\n",
    "# model = load_model(STUB_MODEL)\n",
    "X = np.load(f\"{DATA_PATH}/X_1.npy\")\n",
    "Y = np.load(f\"{DATA_PATH}/Y_1.npy\")\n",
    "\n",
    "model_train(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36S02j3ZEHaB"
   },
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t9n0vUBlGogT",
    "outputId": "8850ecbf-02d5-40bd-e462-96fba56d5aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/filler_detection/train_data/XY_Train/Y_2.npy\n"
     ]
    }
   ],
   "source": [
    "print(f\"{DATA_PATH}/Y_2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6W2RaaAM85_Q",
    "outputId": "b723ca86-da97-41c1-c0ca-a9350a1c3be4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1000, 5490, 129) Y: (1000, 1369, 1)\n"
     ]
    }
   ],
   "source": [
    "# Function to test the model on new data\n",
    "def model_test(model, X_dev, Y_dev):\n",
    "    loss, acc = model.evaluate(X_dev, Y_dev)\n",
    "    print(\"Dev set accuracy = \", acc)\n",
    "\n",
    "X_dev = np.load(f\"{PROJECT_PATH}/X_2.npy\")\n",
    "Y_dev = np.load(f\"{PROJECT_PATH}/Y_2.npy\")\n",
    "print(\"X: {} Y: {}\".format(X_dev.shape, Y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F6uTgE6187gq",
    "outputId": "6e199393-030d-4f9b-a573-8d0ac29337b3"
   },
   "outputs": [],
   "source": [
    "model_test(model, X_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword(filename):\n",
    "    \"\"\"\n",
    "    Function to take filename and generate a prediction vector.\n",
    "    \n",
    "    Argument:\n",
    "    filename -- Audio file to run prediction on\n",
    "    \n",
    "    Returns:\n",
    "    predictions -- Prediction vector with probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    sample_rate, samples = wavfile.read(filename)\n",
    "    _, _, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    # the spectrogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model\n",
    "    x  = x.swapaxes(0,1)\n",
    "    # Reshape the x array in case the time inputs have more columns\n",
    "    x = np.delete(x, np.s_[Tx:], axis=0)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    predictions = model.predict(x)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_filler_word(filename, threshold):\n",
    "    \"\"\"\n",
    "    Function to count the number of times trigger word spoken in audio.\n",
    "    \n",
    "    Arguments:\n",
    "    filename -- Audio file to run prediction on\n",
    "    threshold -- Probability above which trigger word considered present\n",
    "    \"\"\"\n",
    "    audio_clip = AudioSegment.from_wav(filename)\n",
    "    chime = AudioSegment.from_wav(CHIME_FILE)\n",
    "    predictions = detect_triggerword(filename)\n",
    "    Ty = predictions.shape[1]\n",
    "    \n",
    "    # Step 1: Initialize the number of consecutive output steps to 0\n",
    "    consecutive_timesteps = 0\n",
    "    # Step 2: Loop over the output steps in the y\n",
    "    for i in range(Ty):\n",
    "        # Step 3: Increment consecutive output steps\n",
    "        consecutive_timesteps += 1\n",
    "        # Step 4: If prediction is higher than the threshold and more than 75 consecutive output steps have passed\n",
    "        if predictions[0,i,0] > threshold and consecutive_timesteps > 75:\n",
    "            # Step 5: Superpose audio and background using pydub\n",
    "            audio_clip = audio_clip.overlay(chime, position = ((i / Ty) * audio_clip.duration_seconds)*1000)\n",
    "            # Step 6: Reset consecutive output steps to 0\n",
    "            consecutive_timesteps = 0\n",
    "        \n",
    "    audio_clip.export(\"chime_output.wav\", format='wav')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
