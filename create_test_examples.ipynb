{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Dev Numpy Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in c:\\users\\wongj\\anaconda3\\envs\\python and r\\lib\\site-packages (1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "import wave\n",
    "import pylab\n",
    "import pandas as pd\n",
    "from tf_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Import files for trigger-word detection model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_DIRECTORY = \"./raw_data/positive_data/\"\n",
    "BACKGROUND_DIRECTORY = \"./raw_data/background_data/\"\n",
    "NEGATIVES_DIRECTORY = \"./raw_data/google_dataset/\"\n",
    "NEGATIVES_TRUNCATED_DIRECTORY = \"./raw_data/google_dataset_truncated/\"\n",
    "AUDIO_EXAMPLES_DIRECTORY = \"./audio_examples/\"\n",
    "AUDIO_IGNORED_EXAMPLES_DIRECTORY = \"./audio_ignored_examples/\"\n",
    "POSITIVE_EXAMPLE = \"jh_1.wav\"\n",
    "AUDIO_EXAMPLE = \"example_train.wav\"\n",
    "STUB_TRAIN_DIRECTORY = \"./stub_data/XY_Train/\"\n",
    "STUB_DEV_DIRECTORY = \"./stub_data/XY_Dev/\"\n",
    "STUB_MODEL = \"./stub_data/models/tr_model.h5\"\n",
    "CONT_EXAMPLE_DIRECTORY = \"./cont_example/\"\n",
    "DEV_DIRECTORY = \"./raw_data/dev_dataset/\"\n",
    "DEV_CUT_DIRECTORY = \"./raw_data/dev_dataset_cut/\"\n",
    "DEV_NPY_DIRECTORY = \"./raw_data/dev_npy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(AudioSegment.from_file(POSITIVE_DIRECTORY + POSITIVE_EXAMPLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5490 # Based on created training example\n",
    "n_freq = 129 # Based on created training example\n",
    "Ty = 1369 # Based on model.summary() in 1.4 with shape := (Tx, n_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Original Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original insert_ones(y,segment_end_ms)\n",
    "# def insert_ones(y, segment_end_ms):\n",
    "#     \"\"\"\n",
    "#     Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
    "#     should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
    "#     50 followinf labels should be ones.\n",
    "    \n",
    "    \n",
    "#     Arguments:\n",
    "#     y -- numpy array of shape (1, Ty), the labels of the training example\n",
    "#     segment_end_ms -- the end time of the segment in ms\n",
    "    \n",
    "#     Returns:\n",
    "#     y -- updated labels\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # duration of the background (in terms of spectrogram time-steps)\n",
    "#     segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
    "#     print(segment_end_y)\n",
    "    \n",
    "#     # Add 1 to the correct index in the background label (y)\n",
    "#     ### START CODE HERE ### (≈ 3 lines)\n",
    "#     for i in range(segment_end_y + 1, segment_end_y + 51):\n",
    "#         if i < Ty:\n",
    "#             y[0, i] = 1\n",
    "#     ### END CODE HERE ###\n",
    "    \n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original create_training_example(id)\n",
    "# def create_training_example(id):\n",
    "#     \"\"\"\n",
    "#     Creates a training examples with a given background, positives, and negatives with id.\n",
    "    \n",
    "#     Arguments:\n",
    "#     id -- an id is given such that the new files does not replace the previous files\n",
    "    \n",
    "#     Returns:\n",
    "#     x -- the spectrogram of the training example\n",
    "#     y -- the label at each time step of the spectrogram\n",
    "#     \"\"\"\n",
    "#     global BACKGROUND_AUDIONAMES\n",
    "#     global POSITIVES_AUDIONAMES\n",
    "#     global NEGATIVES_AUDIONAMES\n",
    "    \n",
    "#     background = random_background(BACKGROUND_AUDIONAMES)\n",
    "#     positives = random_positives(POSITIVES_AUDIONAMES)\n",
    "#     negatives = random_negatives(NEGATIVES_AUDIONAMES)\n",
    "    \n",
    "#     # Make background quieter\n",
    "#     background = background - 20\n",
    "    \n",
    "#     # Step 1: Initialize y (label vector) of zeros (≈ 1 line)\n",
    "#     y = np.zeros((1, Ty))\n",
    "\n",
    "#     # Step 2: Initialize segment times as empty list (≈ 1 line)\n",
    "#     previous_segments = []    \n",
    "    \n",
    "#     # Step 3: Loop over randomly selected \"activate\" clips and insert in background\n",
    "#     for random_positive in positives:\n",
    "#         if cannot_insert(random_positive, previous_segments):\n",
    "#             return create_training_example(id)\n",
    "#         # Insert the audio clip on the background\n",
    "#         background, segment_time = insert_audio_clip(background, random_positive, previous_segments)\n",
    "#         # Retrieve segment_start and segment_end from segment_time\n",
    "#         segment_start, segment_end = segment_time\n",
    "#         # Insert labels in \"y\"\n",
    "#         y = insert_ones(y, segment_end_ms=segment_end)\n",
    "\n",
    "#     # Step 4: Loop over randomly selected negative clips and insert in background\n",
    "#     for random_negative in negatives:\n",
    "#         if cannot_insert(random_negative, previous_segments):\n",
    "#             return create_training_example(id)\n",
    "#         # Insert the audio clip on the background \n",
    "#         background, _ = insert_audio_clip(background, random_negative, previous_segments)\n",
    "\n",
    "#     # Export new training example \n",
    "#     background = background.set_channels(1)\n",
    "#     background = background.set_frame_rate(123000)\n",
    "    \n",
    "#     TRAIN_PREFIX = \"train_\"\n",
    "#     file_handle = background.export(AUDIO_EXAMPLES_DIRECTORY + TRAIN_PREFIX + str(id) + \".wav\", format=\"wav\")\n",
    "#     # print(\"File (train_\" + str(id) + \".wav) was saved in your directory.\")\n",
    "\n",
    "#     sample_rate, samples = wavfile.read(AUDIO_EXAMPLES_DIRECTORY + TRAIN_PREFIX + str(id) +\".wav\")\n",
    "#     frequencies, times, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "#     return frequencies, times, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original create_X_Y(size,start)\n",
    "# def create_X_Y(size, start):\n",
    "#     i, X, Y = 1, [], []\n",
    "#     for i in range(start, start + size):\n",
    "#         frequencies, times, x, y = create_training_example(i)\n",
    "#         x = np.transpose(x)\n",
    "#         y = np.transpose(y)\n",
    "#         X.append(x)\n",
    "#         Y.append(y)\n",
    "#     return (np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones_for_dev(y, segment_ends):\n",
    "    \"\"\"\n",
    "    Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
    "    should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
    "    50 followinf labels should be ones.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    y -- numpy array of shape (1, Ty), the labels of the training example\n",
    "    segment_end_ms -- A list of end times segments of the dev file in ms\n",
    "    \n",
    "    Returns:\n",
    "    y -- updated labels\n",
    "    \"\"\"\n",
    "\n",
    "    # duration of the background (in terms of spectrogram time-steps)\n",
    "    for segment_end_ms in segment_ends:\n",
    "        segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
    "\n",
    "        # Add 1 to the correct index in the background label (y)\n",
    "        ### START CODE HERE ### (≈ 3 lines)\n",
    "        for i in range(segment_end_y + 1, segment_end_y + 51):\n",
    "             if i < Ty:\n",
    "                 y[0, i] = 1\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_ms(sec):\n",
    "    return sec * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_example(id):\n",
    "    \"\"\"\n",
    "    Creates dev_examples\n",
    "    Arguments:\n",
    "    id -- an id is given such that the new files does not replace the previous files\n",
    "    \n",
    "    Returns:\n",
    "    x -- the spectrogram of the training example\n",
    "    y -- the label at each time step of the spectrogram\n",
    "    \"\"\"\n",
    "    global DEV_CUT_DIRECTORY\n",
    "    \n",
    "    # Step 1: Initialize y (label vector) of zeros (≈ 1 line)\n",
    "    y = np.zeros((1, Ty))\n",
    "    \n",
    "    # Step 2: Import end time segments    \n",
    "    CONT_PREFIX = \"cont_\"\n",
    "    segment_ends = pd.read_csv(DEV_CUT_DIRECTORY + CONT_PREFIX + str(id) + \".txt\", header=None) # Read in the end_time_segments txt\n",
    "    if not str(segment_ends[0].iloc[0]) == 'nan': # If the audio clip has at least one \"basically\". Note: \"NaN\" are given as entries in empty txt\n",
    "        segment_ends[0].apply(np.float)\n",
    "        segment_ends[1] = segment_ends[0].apply(sec_to_ms) # Create a new column of ms\n",
    "        segment_ends = segment_ends[1].tolist() # List of end time segments \n",
    "        \n",
    "        # Step 3: Insert ones\n",
    "        #for segment_end in segment_ends:\n",
    "        y = insert_ones_for_dev(y, segment_ends)\n",
    "    \n",
    "    audio = AudioSegment.from_wav(DEV_CUT_DIRECTORY + CONT_PREFIX + str(id) +\".wav\")\n",
    "    audio = audio.set_frame_rate(123000)\n",
    "    file_handle = audio.export(DEV_CUT_DIRECTORY + CONT_PREFIX + str(id) +\".wav\", format = \"wav\")\n",
    "\n",
    "    sample_rate, samples = wavfile.read(DEV_CUT_DIRECTORY + CONT_PREFIX + str(id) +\".wav\")\n",
    "    frequencies, times, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    return frequencies, times, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case:\n",
    "# frequencies, times, x, y = create_dev_example(44)\n",
    "# c = 0\n",
    "# for i in y[0]:\n",
    "#     #print(i)\n",
    "#     if (i == 1):\n",
    "#        #print(i)\n",
    "#        c += 1\n",
    "# print(c)\n",
    "#IPython.display.Audio(DEV_CUT_DIRECTORY + \"cont_44.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_X_Y(list_of_ids):\n",
    "    \"\"\"\n",
    "    list_of_ids: The list of ids of the desired dev audio files\n",
    "    \n",
    "    Returns:\n",
    "    np.array(X)\n",
    "    np.array(Y)\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for id in list_of_ids:\n",
    "        frequencies, times, x, y = create_dev_example(id)\n",
    "        x = np.transpose(x)\n",
    "        y = np.transpose(y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Numpy Arrays for Dev(Continuous) Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dev_npy(list_of_ids):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    list_of_ids: The list of ids of the desired dev audio files\n",
    "    \n",
    "    Function to save the numpy arrays of the dev audios to DEV_NPY_DIRECTORY\n",
    "    \"\"\"\n",
    "    global DEV_NPY_DIRECTORY\n",
    "    \n",
    "    X, Y = create_dev_X_Y(list_of_ids)\n",
    "    CONT_PREFIX = \"cont_\"\n",
    "    np.save(DEV_NPY_DIRECTORY + CONT_PREFIX + \"X\" + \".npy\", X)\n",
    "    np.save(DEV_NPY_DIRECTORY + CONT_PREFIX + \"Y\" + \".npy\", Y)\n",
    "    print(\"Dimensions of np.array: \" + \"X:{} Y:{}\".format(X.shape, Y.shape))\n",
    "    print(\"np.array of X and Y + saved in \" + DEV_NPY_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of all currently available ids of dev audios\n",
    "list_of_dev_ids = [11,12,13,14,20,21,22,23,24,30,31,32,33,34,35,36,37,38,39,310,40,41,42,43,44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of np.array: X:(25, 5490, 129) Y:(25, 1369, 1)\n",
      "np.array of X and Y + saved in ./raw_data/dev_npy/\n"
     ]
    }
   ],
   "source": [
    "export_dev_npy(list_of_dev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
