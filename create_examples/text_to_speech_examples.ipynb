{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-To-Speech Examples\n",
    "Google text-to-speech API reference [here](https://cloud.google.com/text-to-speech/docs/reference/rpc/google.cloud.texttospeech.v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "from google.cloud import texttospeech\n",
    "from google.auth.exceptions import TransportError\n",
    "from essential_generators import DocumentGenerator\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKGROUND_DIRECTORY = \"../raw_data/background_data/\"\n",
    "AUDIO_IGNORED_EXAMPLES_DIRECTORY = \"../audio_ignored_examples/\"\n",
    "AUDIO_EXAMPLES_DIRECTORY = \"../audio_examples/\"\n",
    "TEST_SET_DIRECTORY = \"../data/test_set/\"\n",
    "TRAINING_SET_DIRECTORY = \"../data/train_set/\"\n",
    "DEV_SET_DIRECTORY = \"../data/dev_set/\"\n",
    "CREDENTIAL_PATH = '../credentials/basically-england-2.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = CREDENTIAL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKGROUND_AUDIONAMES = [name for name in os.listdir(BACKGROUND_DIRECTORY) if name.endswith(\"wav\")]    \n",
    "POSITIVE_SEGMENT = AudioSegment.from_file(AUDIO_EXAMPLES_DIRECTORY + \"basically.wav\")\n",
    "gen = DocumentGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5490 # Based on created training example\n",
    "n_freq = 129 # Based on created training example\n",
    "Ty = 1369 # Based on model.summary() in 1.4 with shape := (Tx, n_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating One Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a 22 words sentence (~10s) with %mean_positives number of 'basically'\n",
    "# TODO: prevent congregation\n",
    "def generate_sentence(mean_positives, filler):\n",
    "    total = 22\n",
    "    num_positives = int(random.gauss(mean_positives, 1))\n",
    "    num_negatives = total - num_positives\n",
    "    words = []\n",
    "    \n",
    "    while len(words) < num_negatives:\n",
    "        para = gen.paragraph()\n",
    "        words += para.split()\n",
    "        \n",
    "    words = words[:num_negatives]\n",
    "    \n",
    "    random_step = 3 + int(random.gauss(2, 1)) # prevent congregation of positive and words being too short to be synthesised\n",
    "    INDEXES = list(range(0, num_negatives - 3, random_step))  # -3 to prevent words being too short to be synthesised\n",
    "    try:\n",
    "        positive_indexes = random.sample(INDEXES, k = num_positives)\n",
    "    except ValueError:\n",
    "        return generate_sentence(mean_positives, filler)\n",
    "    for index in positive_indexes:\n",
    "        words.insert(index, filler)\n",
    "    \n",
    "    assert len(words) == total, \"result need to be exactly 22 words (~10s)\"\n",
    "    sentence = \" \".join(words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Test\n",
    "# sentence = generate_sentence(3, \"basically\")\n",
    "# print(sentence)\n",
    "# sentence.split(\"basically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available voices in texttospeech library\n",
    "\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = CREDENTIAL_PATH\n",
    "# client = texttospeech.TextToSpeechClient()\n",
    "# client.list_voices(language_code=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_text(text, voice_params):\n",
    "    \"\"\"Returns audio segment of synthesized speech from the input string of text.\"\"\"\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = CREDENTIAL_PATH\n",
    "    \n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    input_text = texttospeech.types.SynthesisInput(text=text)\n",
    "    \n",
    "    # Determine the voice characteristics for the audio\n",
    "    language_code = voice_params['language_codes'][0]\n",
    "    name = voice_params['name']\n",
    "    gender = voice_params['ssml_gender']\n",
    "\n",
    "    # Note: the voice can also be specified by name.\n",
    "    # Names of voices can be retrieved with client.list_voices().\n",
    "    voice = texttospeech.types.VoiceSelectionParams(\n",
    "        language_code=language_code,\n",
    "        name=name,\n",
    "        ssml_gender=gender)\n",
    "\n",
    "    audio_config = texttospeech.types.AudioConfig(\n",
    "        audio_encoding=texttospeech.enums.AudioEncoding.LINEAR16)\n",
    "\n",
    "    response = client.synthesize_speech(input_text, voice, audio_config)\n",
    "\n",
    "    temp_filepath = \"temp.wav\"\n",
    "    # The response's audio_content is binary.\n",
    "    with open(temp_filepath, 'wb') as out:\n",
    "        out.write(response.audio_content)\n",
    "        segment = AudioSegment.from_file(temp_filepath)\n",
    "        os.remove(temp_filepath)\n",
    "    \n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Test\n",
    "# output_filepath = \"temp.wav\"\n",
    "# voice_params = {\n",
    "#     \"language_codes\": ['en-US'], \n",
    "#     \"name\": 'en-US-Standard-C', \n",
    "#     \"ssml_gender\": texttospeech.enums.SsmlVoiceGender.FEMALE\n",
    "# }\n",
    "# sentence = \"basically\"\n",
    "# segment = synthesize_text(sentence, voice_params)\n",
    "# segment.export(output_filepath, format='wav')\n",
    "# ipd.Audio(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segment(mean_positives, random_voices=False):\n",
    "    \"\"\" Returns 1) concatenated audio segment and 2) inserted_points (in ms)\n",
    "    \"\"\"\n",
    "    # make sentence with filler word\n",
    "    filler = \"basically\"\n",
    "    sentence = generate_sentence(mean_positives, filler)\n",
    "    \n",
    "    # Client for texttospeech\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "    \n",
    "    # Determine the voice characteristics for the audio\n",
    "    voice_params = {\n",
    "        \"language_codes\": ['en-US'], \n",
    "        \"name\": 'en-US-Standard-C', \n",
    "        \"ssml_gender\": texttospeech.enums.SsmlVoiceGender.FEMALE\n",
    "    }\n",
    "    if random_voices:\n",
    "        random_voice = random.choice(client.list_voices(language_code='en').voices)\n",
    "        voice_params = {\n",
    "            \"language_codes\": random_voice.language_codes, \n",
    "            \"name\": random_voice.name, \n",
    "            \"ssml_gender\": random_voice.ssml_gender\n",
    "        }\n",
    "    \n",
    "    # split by filler word\n",
    "    negative_split = sentence.split(filler)\n",
    "    \n",
    "    # Create filler word\n",
    "    positive_segment = synthesize_text(filler, voice_params)\n",
    "    \n",
    "    # concatenate audio\n",
    "    # filler word is added after each negative, except for the last.\n",
    "    inserted_points = []\n",
    "    segment = AudioSegment.empty()\n",
    "    for i in range(len(negative_split)):\n",
    "        negative = negative_split[i].strip()\n",
    "        try: \n",
    "            if negative != '': segment += synthesize_text(negative, voice_params)\n",
    "        except CouldntDecodeError: \n",
    "            return create_segment(mean_positives, random_voices)\n",
    "        if i != len(negative_split) - 1:\n",
    "            segment += positive_segment\n",
    "            inserted_points.append(segment.duration_seconds * 1000)\n",
    "    \n",
    "    return segment, inserted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_filepath = AUDIO_IGNORED_EXAMPLES_DIRECTORY + \"temp.wav\"\n",
    "# segment, inserted_points = create_segment(3, True)\n",
    "# segment.export(output_filepath)\n",
    "# ipd.Audio(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(segment):\n",
    "    # Trim or pad audio segment to 10000ms\n",
    "    segment = segment[:10000]\n",
    "    padding = AudioSegment.silent(duration=10000)\n",
    "    segment = padding.overlay(segment)\n",
    "    # Set frame rate to 123000\n",
    "    segment = segment.set_channels(1)\n",
    "    segment = segment.set_frame_rate(123000)\n",
    "    \n",
    "    assert math.ceil(segment.duration_seconds) == 10, \"segment needs to be exactly 10s long.\"\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_audio(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_background(background_audionames, debug=False):\n",
    "    \"\"\"\n",
    "    Given a list of background audio names\n",
    "    Return a randomly selected background audio segment\n",
    "    \"\"\"\n",
    "    # generate a random audio\n",
    "    random_audio = np.random.choice(background_audionames, 1, replace=False)[0]\n",
    "    if debug:\n",
    "        print(\"Selecting background file randomly:\\n    - {}\".format(random_audio))\n",
    "    # load audio\n",
    "    global BACKGROUND_DIRECTORY\n",
    "    link = BACKGROUND_DIRECTORY + random_audio\n",
    "    return AudioSegment.from_wav(link)\n",
    "\n",
    "def overlay_background(segment, debug=False):\n",
    "    background = random_background(BACKGROUND_AUDIONAMES, debug)\n",
    "    background = background - 30\n",
    "    return background.overlay(segment, position = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(segment, output_filepath, save):\n",
    "    file_handle = segment.export(output_filepath, format='wav')\n",
    "\n",
    "    sample_rate, samples = wavfile.read(output_filepath)\n",
    "    frequencies, times, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    if save: print(\"File was saved in {}\".format(output_filepath))\n",
    "    else: os.remove(output_filepath)\n",
    "        \n",
    "    return frequencies, times, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create_X(segment, AUDIO_IGNORED_EXAMPLES_DIRECTORY + \"temp.wav\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones(y, segment_end_ms):\n",
    "    \"\"\"\n",
    "    Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
    "    should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
    "    50 followinf labels should be ones.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    y -- numpy array of shape (1, Ty), the labels of the training example\n",
    "    segment_end_ms -- the end time of the segment in ms\n",
    "    \n",
    "    Returns:\n",
    "    y -- updated labels\n",
    "    \"\"\"\n",
    "    # duration of the background (in terms of spectrogram time-steps)\n",
    "    segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
    "    # Add 1 to the correct index in the background label (y)\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    for i in range(segment_end_y + 1, segment_end_y + 51):\n",
    "        if i < Ty:\n",
    "            y[0, i] = 1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y(inserted_points):\n",
    "    # Initialize y (label vector) of zeros (≈ 1 line)\n",
    "    y = np.zeros((1, Ty))\n",
    "    \n",
    "    for point in inserted_points:\n",
    "        y = insert_ones(y, point)\n",
    "        \n",
    "    assert y.shape == (1, Ty), \"y shape needs to follow Ty!\"\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inserted_points = [601.9583333333334, 3147.9166666666665, 6629.875, 10687.833333333334]\n",
    "# y = create_Y(inserted_points)\n",
    "# print(inserted_points) # in ms\n",
    "# plt.plot(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(mean_positives, output_filepath, save=False, random_voices=False):\n",
    "    segment, inserted_points = create_segment(mean_positives, random_voices)\n",
    "    segment = process_audio(segment)\n",
    "    frequencies, times, x = create_X(segment, output_filepath, save)\n",
    "    y = create_Y(inserted_points)\n",
    "    # segment = overlay_background(segment)\n",
    "    \n",
    "    return frequencies, times, x, y, inserted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = AUDIO_IGNORED_EXAMPLES_DIRECTORY + \"temp.wav\"\n",
    "frequencies, times, x, y, inserted_points = create_training_example(4, output_filepath, save=True, random_voices=True)\n",
    "print(\"x: {}\".format(x.shape))\n",
    "print(\"y: {}\".format(y.shape))\n",
    "plt.plot(y[0])\n",
    "print(inserted_points)\n",
    "ipd.Audio(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix refers to the prefix naming of output audio files\n",
    "import time\n",
    "\n",
    "def create_X_Y(size, start, mean_positives, prefix, save=False, random_voices=False):\n",
    "    i, X, Y = start, [], []\n",
    "    for i in range(start, start + size):\n",
    "        output_filepath = prefix + \"_\" + str(i) + \".wav\"\n",
    "        _, _, x, y, _ = create_training_example(mean_positives, output_filepath, save, random_voices)\n",
    "        x = np.transpose(x)\n",
    "        y = np.transpose(y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        print(\"Created example {}...\".format(str(i)))\n",
    "    return (np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = AUDIO_IGNORED_EXAMPLES_DIRECTORY + \"train\"\n",
    "size = 100\n",
    "start = 1\n",
    "mean_positives = 3\n",
    "X, Y = create_X_Y(size, start, mean_positives, prefix, save=True, random_voices=True)\n",
    "\n",
    "print(\"X:{} Y:{}\".format(X.shape, Y.shape))\n",
    "assert X.shape == (size, Tx, n_freq), \"X shape is wrong\"\n",
    "assert Y.shape == (size, Ty, 1), \"X shape is wrong\"\n",
    "\n",
    "np.save(TRAINING_SET_DIRECTORY + \"X_Random_Voices.npy\", X)\n",
    "np.save(TRAINING_SET_DIRECTORY + \"Y_Random_Voices.npy\", Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
