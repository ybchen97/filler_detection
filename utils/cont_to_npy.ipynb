{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(segment, duration):\n",
    "    # Trim or pad audio segment to %duration\n",
    "    segment = segment[:duration]\n",
    "    padding = AudioSegment.silent(duration)\n",
    "    segment = padding.overlay(segment)\n",
    "    # Set frame rate to 123000\n",
    "    segment = segment.set_channels(1)\n",
    "    segment = segment.set_frame_rate(123000)\n",
    "    \n",
    "    assert math.ceil(segment.duration_seconds) == duration / 1000, \"segment needs to be exactly 10s long.\"\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(segment):\n",
    "    output_filepath = \"temp.wav\"\n",
    "    file_handle = segment.export(output_filepath, format='wav')\n",
    "\n",
    "    sample_rate, samples = wavfile.read(output_filepath)\n",
    "    frequencies, times, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    os.remove(output_filepath)\n",
    "        \n",
    "    return frequencies, times, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones(y, segment_end_ms):\n",
    "    \"\"\"\n",
    "    Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
    "    should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
    "    50 followinf labels should be ones.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    y -- numpy array of shape (1, Ty), the labels of the training example\n",
    "    segment_end_ms -- the end time of the segment in ms\n",
    "    \n",
    "    Returns:\n",
    "    y -- updated labels\n",
    "    \"\"\"\n",
    "    # duration of the background (in terms of spectrogram time-steps)\n",
    "    segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
    "    # Add 1 to the correct index in the background label (y)\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    for i in range(segment_end_y + 1, segment_end_y + 51):\n",
    "        if i < Ty:\n",
    "            y[0, i] = 1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y(inserted_points):\n",
    "    # Initialize y (label vector) of zeros (≈ 1 line)\n",
    "    y = np.zeros((1, Ty))\n",
    "    \n",
    "    for point in inserted_points:\n",
    "        y = insert_ones(y, point)\n",
    "        \n",
    "    assert y.shape == (1, Ty), \"y shape needs to follow Ty!\"\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_array(txt_filepath):\n",
    "    \"\"\" Appends text in each line as a sep elt and outputs the result in array.\n",
    "    \"\"\"\n",
    "    with open(txt_filepath, 'r') as f:\n",
    "        x = f.read().splitlines()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.55', '6.44']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# txt_to_array(INPUT_DIRECTORY + TXT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(segment, inserted_points):\n",
    "    segment = process_audio(segment, 10000)\n",
    "    frequencies, times, x = create_X(segment)\n",
    "    \n",
    "    y = create_Y(inserted_points)\n",
    "    return frequencies, times, x, y, inserted_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix refers to the prefix naming of output audio files\n",
    "def create_X_Y(input_directory, output_directory, debug = False):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    txts = [name for name in os.listdir(input_directory) if name.endswith(\".txt\")]\n",
    "    wavs = [name for name in os.listdir(input_directory) if name.endswith(\".wav\")]\n",
    "    txts.sort()\n",
    "    wavs.sort()\n",
    "    total = len(wavs)\n",
    "    \n",
    "    for i in range(total):  \n",
    "        wav = wavs[i]\n",
    "        segment = AudioSegment.from_wav(input_directory + wav)\n",
    "        \n",
    "        txt = txts[i]\n",
    "        arr = txt_to_array(input_directory + txt)\n",
    "        arr_ms = [float(i) * 1000 for i in arr] \n",
    "        if debug: \n",
    "            print(\"Creating example for {} and {}\".format(wavs[i], txts[i]) )\n",
    "            print(\"Inserted points for {} is {}\".format(wavs[i], arr_ms))\n",
    "        _, _, x, y, _ =  create_training_example(segment, arr_ms)\n",
    "        x = np.transpose(x)\n",
    "        y = np.transpose(y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "    assert len(X) == total, \"Not all examples are added to X\"\n",
    "    assert len(Y) == total, \"Not all examples are added to Y\"\n",
    "    \n",
    "    return (np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5490 # Based on created training example\n",
    "n_freq = 129 # Based on created training example\n",
    "Ty = 1369 # Based on model.summary() in 1.4 with shape := (Tx, n_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIRECTORY = \"../ignored_audio_examples/bryan_cont/\"\n",
    "OUTPUT_DIRECTORY = \"../ignored_examples/\"\n",
    "X, Y = create_X_Y(INPUT_DIRECTORY, OUTPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_DIRECTORY = \"../ignored_data/\"\n",
    "np.save(TRAINING_SET_DIRECTORY + \"X_cont.npy\", X)\n",
    "np.save(TRAINING_SET_DIRECTORY + \"Y_cont.npy\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
