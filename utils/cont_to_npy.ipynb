{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(segment, duration):\n",
    "    # Trim or pad audio segment to %duration\n",
    "    segment = segment[:duration]\n",
    "    padding = AudioSegment.silent(duration)\n",
    "    segment = padding.overlay(segment)\n",
    "    # Set frame rate to 123000\n",
    "    segment = segment.set_channels(1)\n",
    "    segment = segment.set_frame_rate(123000)\n",
    "    \n",
    "    assert math.ceil(segment.duration_seconds) == duration / 1000, \"segment needs to be exactly 10s long.\"\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(segment):\n",
    "    output_filepath = \"temp.wav\"\n",
    "    file_handle = segment.export(output_filepath, format='wav')\n",
    "\n",
    "    sample_rate, samples = wavfile.read(output_filepath)\n",
    "    frequencies, times, x = signal.spectrogram(samples, sample_rate)\n",
    "    \n",
    "    os.remove(output_filepath)\n",
    "        \n",
    "    return frequencies, times, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones(y, segment_end_ms):\n",
    "    \"\"\"\n",
    "    Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
    "    should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
    "    50 followinf labels should be ones.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    y -- numpy array of shape (1, Ty), the labels of the training example\n",
    "    segment_end_ms -- the end time of the segment in ms\n",
    "    \n",
    "    Returns:\n",
    "    y -- updated labels\n",
    "    \"\"\"\n",
    "    # duration of the background (in terms of spectrogram time-steps)\n",
    "    segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
    "    # Add 1 to the correct index in the background label (y)\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "    for i in range(segment_end_y + 1, segment_end_y + 51):\n",
    "        if i < Ty:\n",
    "            y[0, i] = 1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y(inserted_points):\n",
    "    # Initialize y (label vector) of zeros (≈ 1 line)\n",
    "    y = np.zeros((1, Ty))\n",
    "    \n",
    "    for point in inserted_points:\n",
    "        y = insert_ones(y, point)\n",
    "        \n",
    "    assert y.shape == (1, Ty), \"y shape needs to follow Ty!\"\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_array(txt_filepath):\n",
    "    \"\"\" Appends text in each line as a sep elt and outputs the result in array.\n",
    "    \"\"\"\n",
    "    with open(txt_filepath, 'r') as f:\n",
    "        x = f.read().splitlines()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.55', '6.44']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_to_array(INPUT_DIRECTORY + TXT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(segment, inserted_points):\n",
    "    segment = process_audio(segment, 10000)\n",
    "    frequencies, times, x = create_X(segment)\n",
    "    \n",
    "    y = create_Y(inserted_points)\n",
    "    return frequencies, times, x, y, inserted_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix refers to the prefix naming of output audio files\n",
    "def create_X_Y(input_directory, output_directory, debug = False):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    txts = [name for name in os.listdir(input_directory) if name.endswith(\".txt\")]\n",
    "    wavs = [name for name in os.listdir(input_directory) if name.endswith(\".wav\")]\n",
    "    txts.sort()\n",
    "    wavs.sort()\n",
    "    total = len(wavs)\n",
    "    \n",
    "    for i in range(total):  \n",
    "        wav = wavs[i]\n",
    "        segment = AudioSegment.from_wav(input_directory + wav)\n",
    "        \n",
    "        txt = txts[i]\n",
    "        arr = txt_to_array(input_directory + txt)\n",
    "        arr_ms = [float(i) * 1000 for i in arr] \n",
    "        if debug: \n",
    "            print(\"Creating example for {} and {}\".format(wavs[i], txts[i]) )\n",
    "            print(\"Inserted points for {} is {}\".format(wavs[i], arr_ms))\n",
    "        _, _, x, y, _ =  create_training_example(segment, arr_ms)\n",
    "        x = np.transpose(x)\n",
    "        y = np.transpose(y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "    assert X.shape[0] == total, \"Not all examples are added to X\"\n",
    "    assert Y.shape[0] == total, \"Not all examples are added to Y\"\n",
    "    \n",
    "    return (np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5490 # Based on created training example\n",
    "n_freq = 129 # Based on created training example\n",
    "Ty = 1369 # Based on model.summary() in 1.4 with shape := (Tx, n_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating example for aru_1.wav and aru_1.txt\n",
      "Inserted points for aru_1.wav is [715.0, 9470.0]\n",
      "Creating example for aru_10.wav and aru_10.txt\n",
      "Inserted points for aru_10.wav is [3600.0, 8790.0]\n",
      "Creating example for aru_11.wav and aru_11.txt\n",
      "Inserted points for aru_11.wav is [3290.0, 7720.0]\n",
      "Creating example for aru_12.wav and aru_12.txt\n",
      "Inserted points for aru_12.wav is [1920.0]\n",
      "Creating example for aru_13.wav and aru_13.txt\n",
      "Inserted points for aru_13.wav is [4510.0, 7520.0]\n",
      "Creating example for aru_2.wav and aru_2.txt\n",
      "Inserted points for aru_2.wav is [3320.0, 7260.0]\n",
      "Creating example for aru_3.wav and aru_3.txt\n",
      "Inserted points for aru_3.wav is [2890.0, 8440.0]\n",
      "Creating example for aru_4.wav and aru_4.txt\n",
      "Inserted points for aru_4.wav is [3550.0, 6440.0]\n",
      "Creating example for aru_5.wav and aru_5.txt\n",
      "Inserted points for aru_5.wav is [4850.0, 8950.0]\n",
      "Creating example for aru_6.wav and aru_6.txt\n",
      "Inserted points for aru_6.wav is [1600.0, 7120.0]\n",
      "Creating example for aru_7.wav and aru_7.txt\n",
      "Inserted points for aru_7.wav is [7860.0]\n",
      "Creating example for aru_8.wav and aru_8.txt\n",
      "Inserted points for aru_8.wav is [1540.0, 7090.0, 10000.0]\n",
      "Creating example for aru_9.wav and aru_9.txt\n",
      "Inserted points for aru_9.wav is [132.0, 6380.0]\n",
      "Creating example for chai_1.wav and chai_1.txt\n",
      "Inserted points for chai_1.wav is [3800.0, 7500.0, 9300.0]\n",
      "Creating example for chai_10.wav and chai_10.txt\n",
      "Inserted points for chai_10.wav is [3570.0, 6900.0]\n",
      "Creating example for chai_11.wav and chai_11.txt\n",
      "Inserted points for chai_11.wav is [3930.0, 8330.0]\n",
      "Creating example for chai_12.wav and chai_12.txt\n",
      "Inserted points for chai_12.wav is [2570.0, 9330.0]\n",
      "Creating example for chai_13.wav and chai_13.txt\n",
      "Inserted points for chai_13.wav is [1780.0, 5390.0, 7200.0]\n",
      "Creating example for chai_2.wav and chai_2.txt\n",
      "Inserted points for chai_2.wav is [2900.0, 9000.0]\n",
      "Creating example for chai_3.wav and chai_3.txt\n",
      "Inserted points for chai_3.wav is [1830.0, 5550.0]\n",
      "Creating example for chai_4.wav and chai_4.txt\n",
      "Inserted points for chai_4.wav is [3600.0, 9800.0]\n",
      "Creating example for chai_5.wav and chai_5.txt\n",
      "Inserted points for chai_5.wav is [3100.0, 8300.0]\n",
      "Creating example for chai_6.wav and chai_6.txt\n",
      "Inserted points for chai_6.wav is [2900.0, 6250.0, 9400.0]\n",
      "Creating example for chai_7.wav and chai_7.txt\n",
      "Inserted points for chai_7.wav is [3800.0, 9100.0]\n",
      "Creating example for chai_8.wav and chai_8.txt\n",
      "Inserted points for chai_8.wav is [3250.0, 9100.0]\n",
      "Creating example for chai_9.wav and chai_9.txt\n",
      "Inserted points for chai_9.wav is [2750.0, 8500.0]\n"
     ]
    },
    {
     "ename": "CouldntDecodeError",
     "evalue": "Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nb'ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\\n  built with Apple clang version 11.0.0 (clang-1100.0.33.17)\\n  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.2.2_2 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librubberband --enable-libsnappy --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-libsoxr --enable-videotoolbox --disable-libjack --disable-indev=jack\\n  libavutil      56. 31.100 / 56. 31.100\\n  libavcodec     58. 54.100 / 58. 54.100\\n  libavformat    58. 29.100 / 58. 29.100\\n  libavdevice    58.  8.100 / 58.  8.100\\n  libavfilter     7. 57.100 /  7. 57.100\\n  libavresample   4.  0.  0 /  4.  0.  0\\n  libswscale      5.  5.100 /  5.  5.100\\n  libswresample   3.  5.100 /  3.  5.100\\n  libpostproc    55.  5.100 / 55.  5.100\\n[wav @ 0x7f8429000000] invalid start code [0][0][0][0] in RIFF header\\n../ignored_audio_examples/bryan_cont/yb_1.wav: Invalid data found when processing input\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCouldntDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-0be3a72a3b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mINPUT_DIRECTORY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../ignored_audio_examples/bryan_cont/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mOUTPUT_DIRECTORY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../ignored_examples/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_X_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIRECTORY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIRECTORY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-2f5b4c7e5df3>\u001b[0m in \u001b[0;36mcreate_X_Y\u001b[0;34m(input_directory, output_directory, debug)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_wav\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m             raise CouldntDecodeError(\n\u001b[1;32m    703\u001b[0m                 \"Decoding failed. ffmpeg returned error code: {0}\\n\\nOutput from ffmpeg/avlib:\\n\\n{1}\".format(\n\u001b[0;32m--> 704\u001b[0;31m                     p.returncode, p_err))\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCouldntDecodeError\u001b[0m: Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nb'ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\\n  built with Apple clang version 11.0.0 (clang-1100.0.33.17)\\n  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.2.2_2 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librubberband --enable-libsnappy --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-libsoxr --enable-videotoolbox --disable-libjack --disable-indev=jack\\n  libavutil      56. 31.100 / 56. 31.100\\n  libavcodec     58. 54.100 / 58. 54.100\\n  libavformat    58. 29.100 / 58. 29.100\\n  libavdevice    58.  8.100 / 58.  8.100\\n  libavfilter     7. 57.100 /  7. 57.100\\n  libavresample   4.  0.  0 /  4.  0.  0\\n  libswscale      5.  5.100 /  5.  5.100\\n  libswresample   3.  5.100 /  3.  5.100\\n  libpostproc    55.  5.100 / 55.  5.100\\n[wav @ 0x7f8429000000] invalid start code [0][0][0][0] in RIFF header\\n../ignored_audio_examples/bryan_cont/yb_1.wav: Invalid data found when processing input\\n'"
     ]
    }
   ],
   "source": [
    "INPUT_DIRECTORY = \"../ignored_audio_examples/bryan_cont/\"\n",
    "OUTPUT_DIRECTORY = \"../ignored_examples/\"\n",
    "X, Y = create_X_Y(INPUT_DIRECTORY, OUTPUT_DIRECTORY, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
